import logging
from bot.telegram_bot import TG_TOKEN
from celery import shared_task
from django.db import transaction
from .models import CoinSnapshot, Subscription, CoinDailyStat, NewsArticle, NewsSentiment, PriceEvent
import numpy as np
import requests
from datetime import datetime, timedelta
import time
import os
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer 


# ============================================
# –ó–∞–¥–∞—á–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ –º–æ–Ω–µ—Ç–∞—Ö –∏–∑ CoinGecko
# ============================================

@shared_task
def update_coin_snapshots():
    url = "https://api.coingecko.com/api/v3/coins/markets"
    params = {
        "vs_currency": "usd",
        "order": "market_cap_desc",
        "per_page": 20,
        "page": 1,
        "sparkline": "false"
    }
    try:
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        coins_data = response.json()

        with transaction.atomic():
            for coin in coins_data:
                CoinSnapshot.objects.update_or_create(
                    coingecko_id=coin["id"],
                    defaults={
                        "name": coin["name"],
                        "symbol": coin["symbol"],
                        "price": coin["current_price"],
                        "market_cap": coin.get("market_cap")  # –¥–æ–±–∞–≤–ª–µ–Ω–æ
                    }
                )

        print(f"[{datetime.now()}] –û–±–Ω–æ–≤–ª–µ–Ω–æ {len(coins_data)} –º–æ–Ω–µ—Ç")
        return f"–û–±–Ω–æ–≤–ª–µ–Ω–æ {len(coins_data)} –º–æ–Ω–µ—Ç"

    except requests.RequestException as e:
        print(f"[{datetime.now()}] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ API: {e}")
        return f"–û—à–∏–±–∫–∞: {e}"



# ============================================
# # –ó–∞–¥–∞—á–∞ –¥–ª—è —Å–±–æ—Ä–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω –ø–æ –¥–Ω—è–º
# ============================================

@shared_task
def collect_historical_prices(days=30):
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ü–µ–Ω—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π
    """
    coins = CoinSnapshot.objects.all()[:10]  # –£–º–µ–Ω—å—à–∏–ª –¥–æ 10 –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    
    for coin in coins:
        try:
            url = f"https://api.coingecko.com/api/v3/coins/{coin.coingecko_id}/market_chart"
            params = {
                "vs_currency": "usd",
                "days": days,
                "interval": "daily"
            }
            
            response = requests.get(url, params=params, timeout=15)
            response.raise_for_status()
            data = response.json()
            
            prices = data.get("prices", [])
            market_caps = data.get("market_caps", [])
            volumes = data.get("total_volumes", [])
            
            for i in range(len(prices)):
                timestamp = prices[i][0] / 1000
                date = datetime.utcfromtimestamp(timestamp).date()
                price = prices[i][1]
                market_cap = market_caps[i][1] if i < len(market_caps) else None
                volume = volumes[i][1] if i < len(volumes) else None
                
                # –í—ã—á–∏—Å–ª—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã
                prev_price = prices[i-1][1] if i > 0 else price
                price_change_percent = ((price - prev_price) / prev_price) * 100 if prev_price else 0
                
                CoinDailyStat.objects.update_or_create(
                    coin=coin,
                    date=date,
                    defaults={
                        "price": price,
                        "market_cap": market_cap,
                        "volume": volume,
                        "price_change_percent": price_change_percent
                    }
                )
            
            print(f"‚úÖ {coin.symbol.upper()} - –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(prices)} –¥–Ω–µ–π –∏—Å—Ç–æ—Ä–∏–∏ —Ü–µ–Ω")
            time.sleep(60)  # ‚Üê –ò–ó–ú–ï–ù–ò–õ –° 2 –ù–ê 5 –°–ï–ö–£–ù–î!
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª—è {coin.symbol}: {e}")
    
    return f"–°–æ–±—Ä–∞–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(coins)} –º–æ–Ω–µ—Ç"


# ============================================
# –ó–∞–¥–∞—á–∏ –¥–ª—è —Å–±–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
# ============================================

@shared_task
def collect_historical_news(days=30):
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π —á–µ—Ä–µ–∑ NewsAPI.org
    –° –†–ê–°–®–ò–†–ï–ù–ù–´–ú–ò –∑–∞–ø—Ä–æ—Å–∞–º–∏
    """
    from newsapi import NewsApiClient
    
    NEWSAPI_KEY = os.environ.get('NEWSAPI_KEY')
    if not NEWSAPI_KEY:
        return "NEWSAPI_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω"
    
    newsapi = NewsApiClient(api_key=NEWSAPI_KEY)
    coins = CoinSnapshot.objects.order_by('-market_cap')[:10]
    total_articles = 0
    
    for coin in coins:
        try:
            # –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –í–ê–†–ò–ê–ù–¢–´ –ó–ê–ü–†–û–°–û–í –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–Ω–µ—Ç—ã
            queries = [
                f"{coin.name} cryptocurrency",
                f"{coin.symbol.upper()} price",
                f"{coin.name} {coin.symbol.upper()}",
                f"{coin.name} news",
                f"{coin.symbol.upper()} trading",
            ]
            
            from_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')
            to_date = datetime.now().strftime('%Y-%m-%d')
            
            for query in queries:
                try:
                    all_articles = newsapi.get_everything(
                        q=query,
                        from_param=from_date,
                        to=to_date,
                        language='en',
                        sort_by='publishedAt',
                        page_size=100
                    )
                    
                    articles = all_articles.get('articles', [])
                    saved_count = 0
                    
                    for article in articles:
                        try:
                            if not article.get('url') or not article.get('title'):
                                continue
                            
                            published_str = article.get('publishedAt', '')
                            if published_str:
                                published_at = datetime.strptime(published_str, '%Y-%m-%dT%H:%M:%SZ')
                            else:
                                continue
                            
                            obj, created = NewsArticle.objects.get_or_create(
                                url=article['url'],
                                defaults={
                                    'coin': coin,
                                    'title': article['title'][:500],
                                    'description': article.get('description', '')[:1000] if article.get('description') else '',
                                    'source': article.get('source', {}).get('name', 'Unknown'),
                                    'published_at': published_at,
                                    'news_type': 'financial'
                                }
                            )
                            
                            if created:
                                saved_count += 1
                                
                        except Exception:
                            continue
                    
                    total_articles += saved_count
                    print(f"  '{query}' - {saved_count} –Ω–æ–≤—ã—Ö")
                    time.sleep(1)
                    
                except Exception as e:
                    print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–ª—è '{query}': {e}")
                    continue
            
            print(f"‚úÖ {coin.symbol.upper()} - –≤—Å–µ–≥–æ {total_articles} –Ω–æ–≤–æ—Å—Ç–µ–π")
            time.sleep(2)
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª—è {coin.symbol}: {e}")
            continue
    
    return f"–°–æ–±—Ä–∞–Ω–æ {total_articles} –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"

@shared_task
def collect_political_news():
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤–ª–∏—è—é—â–∏–µ –Ω–∞ –∫—Ä–∏–ø—Ç–æ—Ä—ã–Ω–æ–∫
    - –†–µ–≥—É–ª—è—Ü–∏–∏
    - –ì–µ–æ–ø–æ–ª–∏—Ç–∏–∫–∞
    - –ú–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏–∫–∞
    - –°—É–¥–µ–±–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è
    """
    from newsapi import NewsApiClient
    
    NEWSAPI_KEY = os.environ.get('NEWSAPI_KEY')
    if not NEWSAPI_KEY:
        return "NEWSAPI_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω"
    
    newsapi = NewsApiClient(api_key=NEWSAPI_KEY)
    coins = CoinSnapshot.objects.order_by('-market_cap')[:10]
    
    # –ü–û–õ–ò–¢–ò–ß–ï–°–ö–ò–ï –¢–ï–ú–´ –≤–ª–∏—è—é—â–∏–µ –Ω–∞ –∫—Ä–∏–ø—Ç—É
    political_queries = [
        # –†–µ–≥—É–ª—è—Ü–∏–∏
        'SEC cryptocurrency regulation',
        'crypto regulation bill congress',
        'European Union crypto regulation MiCA',
        'cryptocurrency ban government',
        
        # –°—É–¥–µ–±–Ω—ã–µ –¥–µ–ª–∞
        'Ripple SEC lawsuit',
        'cryptocurrency court case',
        'crypto exchange lawsuit',
        
        # –ú–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏–∫–∞
        'Federal Reserve interest rate crypto',
        'inflation cryptocurrency',
        'economic recession bitcoin',
        
        # –ì–µ–æ–ø–æ–ª–∏—Ç–∏–∫–∞
        'cryptocurrency sanctions Russia',
        'China cryptocurrency ban',
        'El Salvador bitcoin adoption',
        
        # –ü–æ–ª–∏—Ç–∏–∫–∞
        'Biden cryptocurrency policy',
        'Trump bitcoin',
        'crypto election campaign',
    ]
    
    total_articles = 0
    from_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
    
    for query in political_queries:
        try:
            results = newsapi.get_everything(
                q=query,
                from_param=from_date,
                language='en',
                sort_by='relevancy',
                page_size=15  # –ø–æ 15 –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Ç–µ–º—É
            )
            
            articles = results.get('articles', [])
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –í–°–ï–• –º–æ–Ω–µ—Ç (–ø–æ–ª–∏—Ç–∏–∫–∞ –≤–ª–∏—è–µ—Ç –Ω–∞ –≤–µ—Å—å —Ä—ã–Ω–æ–∫)
            for coin in coins:
                for article in articles:
                    try:
                        if not article.get('url') or not article.get('title'):
                            continue
                        
                        published_str = article.get('publishedAt', '')
                        if published_str:
                            published_at = datetime.strptime(published_str, '%Y-%m-%dT%H:%M:%SZ')
                        else:
                            continue
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∫—É —á—Ç–æ —ç—Ç–æ –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –Ω–æ–≤–æ—Å—Ç—å
                        description = article.get('description', '') or ''
                        title = f"[POLITICAL] {article['title']}"[:500]
                        obj, created = NewsArticle.objects.get_or_create(
                            url=article['url'],
                            defaults={
                                'coin': coin,
                                'title': article['title'][:500],  # –ë–ï–ó [POLITICAL]!
                                'description': description[:1000],
                                'source': article.get('source', {}).get('name', 'Political News'),
                                'published_at': published_at,
                                'news_type': 'political'  # –î–û–ë–ê–í–ò–õ–ò
                            }
                        )

                        
                        if created:
                            total_articles += 1
                            
                    except Exception as e:
                        continue
            
            print(f"‚úÖ '{query[:40]}...' - {len(articles)} —Å—Ç–∞—Ç–µ–π")
            time.sleep(3)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª—è '{query}': {e}")
            continue
    
    return f"–°–æ–±—Ä–∞–Ω–æ {total_articles} –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"

@shared_task
def collect_market_news():
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –æ–±—â–µ—Ä—ã–Ω–æ—á–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –ø—Ä–æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã
    –≠—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏ –±—É–¥—É—Ç —Å–≤—è–∑–∞–Ω—ã —Å–æ –í–°–ï–ú–ò –º–æ–Ω–µ—Ç–∞–º–∏
    """
    from newsapi import NewsApiClient
    
    NEWSAPI_KEY = os.environ.get('NEWSAPI_KEY')
    if not NEWSAPI_KEY:
        return "NEWSAPI_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω"
    
    newsapi = NewsApiClient(api_key=NEWSAPI_KEY)
    
    # –û–±—â–µ—Ä—ã–Ω–æ—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    market_queries = [
        'cryptocurrency market crash',
        'crypto regulation SEC',
        'bitcoin ETF approval',
        'cryptocurrency adoption',
        'crypto market analysis',
    ]
    
    total_articles = 0
    coins = CoinSnapshot.objects.all()[:10]  
    
    for query in market_queries:
        try:
            from_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
            
            all_articles = newsapi.get_everything(
                q=query,
                from_param=from_date,
                language='en',
                sort_by='relevancy',
                page_size=20  # –ø–æ 20 –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ –∑–∞–ø—Ä–æ—Å
            )
            
            articles = all_articles.get('articles', [])
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ö–ê–ñ–î–û–ô –º–æ–Ω–µ—Ç—ã (–æ–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç)
            for coin in coins:
                for article in articles:
                    try:
                        if not article.get('url') or not article.get('title'):
                            continue
                        
                        published_str = article.get('publishedAt', '')
                        if published_str:
                            published_at = datetime.strptime(published_str, '%Y-%m-%dT%H:%M:%SZ')
                        else:
                            continue
                        obj, created = NewsArticle.objects.get_or_create(
                            url=article['url'],
                            defaults={
                                'coin': coin,
                                'title': article['title'][:500],
                                'description': description[:1000],
                                'source': article.get('source', {}).get('name', 'Market News'),
                                'published_at': published_at,
                                'news_type': 'market'  # –î–û–ë–ê–í–ò–õ–ò
                            }
                        )

                        
                        if created:
                            total_articles += 1
                            
                    except Exception as e:
                        continue
            
            print(f"‚úÖ Query '{query}' - —Å–æ–±—Ä–∞–Ω–æ {len(articles)} —Å—Ç–∞—Ç–µ–π")
            time.sleep(2)
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{query}': {e}")
            continue
    
    return f"–°–æ–±—Ä–∞–Ω–æ {total_articles} –æ–±—â–µ—Ä—ã–Ω–æ—á–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"

@shared_task
def collect_crypto_news_extended():
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞–º
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    """
    from newsapi import NewsApiClient
    
    NEWSAPI_KEY = os.environ.get('NEWSAPI_KEY')
    if not NEWSAPI_KEY:
        return "NEWSAPI_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω"
    
    newsapi = NewsApiClient(api_key=NEWSAPI_KEY)
    coins = CoinSnapshot.objects.all()[:10]  # 15 –º–æ–Ω–µ—Ç
    total_articles = 0
    
    # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∫—Ä–∏–ø—Ç–æ-–∏—Å—Ç–æ—á–Ω–∏–∫–∏
    crypto_sources = [
        'crypto-coins-news',
        'techcrunch',
        'the-verge',
        'wired',
        'ars-technica'
    ]
    
    for coin in coins:
        try:
            # –ó–∞–ø—Ä–æ—Å 1: –û–±—â–∏–π –ø–æ–∏—Å–∫
            query = f'"{coin.name}" OR "{coin.symbol.upper()}" cryptocurrency'
            from_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
            
            results = newsapi.get_everything(
                q=query,
                from_param=from_date,
                language='en',
                sort_by='relevancy',  # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                page_size=50
            )
            
            for article in results.get('articles', []):
                try:
                    if not article.get('url') or not article.get('title'):
                        continue
                        
                    published_at = datetime.strptime(
                        article['publishedAt'], 
                        '%Y-%m-%dT%H:%M:%SZ'
                    )
                    
                    obj, created = NewsArticle.objects.get_or_create(
                        url=article['url'],
                        defaults={
                            'coin': coin,
                            'title': article['title'][:500],
                            'description': article.get('description', '')[:1000] if article.get('description') else '',
                            'source': article.get('source', {}).get('name', 'Unknown'),
                            'published_at': published_at
                        }
                    )
                    
                    if created:
                        total_articles += 1
                        
                except Exception:
                    continue
            
            # –ó–∞–ø—Ä–æ—Å 2: –ü–æ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
            try:
                source_results = newsapi.get_everything(
                    q=coin.name,
                    sources=','.join(crypto_sources),
                    from_param=from_date,
                    language='en',
                    page_size=30
                )
                
                for article in source_results.get('articles', []):
                    try:
                        if not article.get('url'):
                            continue
                            
                        published_at = datetime.strptime(
                            article['publishedAt'], 
                            '%Y-%m-%dT%H:%M:%SZ'
                        )
                        
                        NewsArticle.objects.get_or_create(
                            url=article['url'],
                            defaults={
                                'coin': coin,
                                'title': article['title'][:500],
                                'description': article.get('description', '')[:1000] if article.get('description') else '',
                                'source': article.get('source', {}).get('name', 'Unknown'),
                                'published_at': published_at
                            }
                        )
                    except Exception:
                        continue
                        
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è {coin.symbol}: {e}")
            
            print(f"‚úÖ {coin.symbol.upper()} - –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
            time.sleep(2)  # –ø–∞—É–∑–∞ –º–µ–∂–¥—É –º–æ–Ω–µ—Ç–∞–º–∏
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª—è {coin.symbol}: {e}")
            continue
    
    return f"–°–æ–±—Ä–∞–Ω–æ {total_articles} –Ω–æ–≤–æ—Å—Ç–µ–π"




# –ê–ù–ê–õ–ò–ó –¢–û–ù–ê–õ–¨–ù–û–°–¢–ò –ù–û–í–û–°–¢–ï–ô
# ============================================

@shared_task
def analyze_all_sentiment():
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –≤—Å–µ—Ö –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç VADER –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö/–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö/–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
    """
    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
    
    analyzer = SentimentIntensityAnalyzer()
    
    # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤–æ—Å—Ç–∏ –ë–ï–ó –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
    articles = NewsArticle.objects.filter(newssentiment__isnull=True)
    total_articles = articles.count()
    
    if total_articles == 0:
        return "–í—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ —É–∂–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã"
    
    print(f"üí≠ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å {total_articles} –Ω–æ–≤–æ—Å—Ç–µ–π...")
    
    analyzed_count = 0
    
    for article in articles:
        try:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            text = f"{article.title} {article.description or ''}"
            
            # VADER –∞–Ω–∞–ª–∏–∑
            scores = analyzer.polarity_scores(text)
            
            # compound: –æ—Ç -1 (–æ—á–µ–Ω—å –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ) –¥–æ +1 (–æ—á–µ–Ω—å –ø–æ–∑–∏—Ç–∏–≤–Ω–æ)
            sentiment_score = scores['compound']
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            if sentiment_score >= 0.05:
                label = 'positive'
            elif sentiment_score <= -0.05:
                label = 'negative'
            else:
                label = 'neutral'
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
            NewsSentiment.objects.create(
                article=article,
                sentiment_score=sentiment_score,
                sentiment_label=label,
                confidence=max(scores['pos'], scores['neg'], scores['neu'])
            )
            
            analyzed_count += 1
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 100 —Å—Ç–∞—Ç–µ–π
            if analyzed_count % 100 == 0:
                print(f"  –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {analyzed_count}/{total_articles}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç–∞—Ç—å–∏ {article.id}: {e}")
            continue
    
    print(f"‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {analyzed_count} –∏–∑ {total_articles} —Å—Ç–∞—Ç–µ–π")
    return f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {analyzed_count} —Å—Ç–∞—Ç–µ–π"


# ============================================
# –ü–û–ò–°–ö –ê–ù–û–ú–ê–õ–ò–ô –í –¶–ï–ù–ê–•
# ============================================

@shared_task
def detect_all_anomalies(threshold_percent=1.5):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –∞–Ω–æ–º–∞–ª–∏–∏ (—Ä–µ–∑–∫–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è) —Ü–µ–Ω –∏ —Å–≤—è–∑—ã–≤–∞–µ—Ç –∏—Ö —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    - threshold_percent: –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã –≤ % –¥–ª—è —Å—á–∏—Ç–∞–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–µ–π
                         (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1.5%)
    
    –ê–ª–≥–æ—Ä–∏—Ç–º:
    1. –î–ª—è –∫–∞–∂–¥–æ–π –º–æ–Ω–µ—Ç—ã –±–µ—Ä–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ü–µ–Ω
    2. –ù–∞—Ö–æ–¥–∏–º –¥–Ω–∏ –≥–¥–µ —Ü–µ–Ω–∞ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å –±–æ–ª–µ–µ —á–µ–º –Ω–∞ threshold_percent
    3. –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ –Ω–æ–≤–æ—Å—Ç–µ–π –±—ã–ª–æ –∑–∞ 3 –¥–Ω—è –î–û —ç—Ç–æ–≥–æ —Å–æ–±—ã—Ç–∏—è
    4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –∞–Ω–æ–º–∞–ª–∏—é (spike –∏–ª–∏ crash)
    """
    coins = CoinSnapshot.objects.all()
    anomaly_count = 0
    
    print(f"‚ö° –ü–æ–∏—Å–∫ –∞–Ω–æ–º–∞–ª–∏–π (–ø–æ—Ä–æ–≥: {threshold_percent}%) –¥–ª—è {coins.count()} –º–æ–Ω–µ—Ç...")
    
    for coin in coins:
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ü–µ–Ω, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø–æ –¥–∞—Ç–µ
            stats = list(
                CoinDailyStat.objects.filter(coin=coin).order_by('date')
            )
            
            if len(stats) < 2:
                print(f"‚ö†Ô∏è  {coin.symbol.upper()} - –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö (< 2 –¥–Ω–µ–π)")
                continue
            
            coin_anomalies = 0
            
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—ã–π –¥–µ–Ω—å —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º
            for i in range(1, len(stats)):
                try:
                    prev_stat = stats[i-1]
                    curr_stat = stats[i]
                    
                    prev_price = float(prev_stat.price)
                    curr_price = float(curr_stat.price)
                    
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ —Ü–µ–Ω–∞ = 0
                    if prev_price == 0:
                        continue
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
                    change_percent = ((curr_price - prev_price) / prev_price) * 100
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥ –∞–Ω–æ–º–∞–ª–∏–∏
                    if abs(change_percent) > threshold_percent:
                        
                        # –°—á–∏—Ç–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ 3 –¥–Ω—è –î–û —Å–æ–±—ã—Ç–∏—è
                        news_period_start = curr_stat.date - timedelta(days=3)
                        news_period_end = curr_stat.date
                        
                        news_count = NewsArticle.objects.filter(
                            coin=coin,
                            published_at__date__range=[news_period_start, news_period_end]
                        ).count()
                        
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–æ–±—ã—Ç–∏—è
                        if change_percent > 0:
                            event_type = 'spike'  # —Ä–æ—Å—Ç
                        else:
                            event_type = 'crash'  # –ø–∞–¥–µ–Ω–∏–µ
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ
                        event, created = PriceEvent.objects.update_or_create(
                            coin=coin,
                            date=curr_stat.date,
                            defaults={
                                'event_type': event_type,
                                'price_change_percent': change_percent,
                                'price_before': prev_price,
                                'price_after': curr_price,
                                'is_anomaly': True,
                                'news_count': news_count
                            }
                        )
                        
                        if created:
                            anomaly_count += 1
                            coin_anomalies += 1
                
                except Exception as e:
                    print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–Ω—è {curr_stat.date}: {e}")
                    continue
            
            if coin_anomalies > 0:
                print(f"‚úÖ {coin.symbol.upper()} - –Ω–∞–π–¥–µ–Ω–æ {coin_anomalies} –∞–Ω–æ–º–∞–ª–∏–π")
            else:
                print(f"‚ÑπÔ∏è  {coin.symbol.upper()} - –∞–Ω–æ–º–∞–ª–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª—è {coin.symbol}: {e}")
            continue
    
    print(f"\n‚úÖ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {anomaly_count} –Ω–æ–≤—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π")
    return f"–ù–∞–π–¥–µ–Ω–æ {anomaly_count} –∞–Ω–æ–º–∞–ª–∏–π"


# ============================================
# –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–ù–û–ú–ê–õ–ò–ô (–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û)
# ============================================

@shared_task
def get_anomalies_stats():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–º –∞–Ω–æ–º–∞–ª–∏—è–º
    –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º
    """
    from django.db.models import Count, Avg, Max, Min
    
    total_events = PriceEvent.objects.filter(is_anomaly=True).count()
    
    if total_events == 0:
        return "–ê–Ω–æ–º–∞–ª–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ó–∞–ø—É—Å—Ç–∏—Ç–µ detect_all_anomalies()"
    
    print("="*60)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–ù–û–ú–ê–õ–ò–ô")
    print("="*60)
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüéØ –í—Å–µ–≥–æ –∞–Ω–æ–º–∞–ª–∏–π: {total_events}")
    
    # –ü–æ —Ç–∏–ø–∞–º
    spikes = PriceEvent.objects.filter(event_type='spike', is_anomaly=True).count()
    crashes = PriceEvent.objects.filter(event_type='crash', is_anomaly=True).count()
    print(f"\nüìà –¢–∏–ø—ã:")
    print(f"  –†–æ—Å—Ç (spike):  {spikes} ({spikes/total_events*100:.1f}%)")
    print(f"  –ü–∞–¥–µ–Ω–∏–µ (crash): {crashes} ({crashes/total_events*100:.1f}%)")
    
    # –ü–æ –º–æ–Ω–µ—Ç–∞–º
    print(f"\nü™ô –ü–æ –º–æ–Ω–µ—Ç–∞–º:")
    by_coin = PriceEvent.objects.filter(is_anomaly=True).values(
        'coin__symbol', 'coin__name'
    ).annotate(
        count=Count('id'),
        avg_change=Avg('price_change_percent'),
        max_change=Max('price_change_percent'),
        min_change=Min('price_change_percent'),
        avg_news=Avg('news_count')
    ).order_by('-count')
    
    for item in by_coin:
        print(f"  {item['coin__symbol'].upper():8} - "
              f"{item['count']:2} —Å–æ–±—ã—Ç–∏–π, "
              f"—Å—Ä–µ–¥–Ω–µ–µ –∏–∑–º: {item['avg_change']:+.2f}%, "
              f"–Ω–æ–≤–æ—Å—Ç–µ–π: {item['avg_news']:.1f}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    changes = PriceEvent.objects.filter(is_anomaly=True).aggregate(
        avg=Avg('price_change_percent'),
        max=Max('price_change_percent'),
        min=Min('price_change_percent')
    )
    print(f"\nüìä –ò–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω:")
    print(f"  –°—Ä–µ–¥–Ω–µ–µ: {changes['avg']:+.2f}%")
    print(f"  –ú–∞–∫—Å–∏–º—É–º: {changes['max']:+.2f}%")
    print(f"  –ú–∏–Ω–∏–º—É–º: {changes['min']:+.2f}%")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
    news_stats = PriceEvent.objects.filter(is_anomaly=True).aggregate(
        avg_news=Avg('news_count'),
        max_news=Max('news_count'),
        min_news=Min('news_count')
    )
    print(f"\nüì∞ –ù–æ–≤–æ—Å—Ç–∏ (–∑–∞ 3 –¥–Ω—è –¥–æ —Å–æ–±—ã—Ç–∏—è):")
    print(f"  –°—Ä–µ–¥–Ω–µ–µ: {news_stats['avg_news']:.1f}")
    print(f"  –ú–∞–∫—Å–∏–º—É–º: {news_stats['max_news']}")
    print(f"  –ú–∏–Ω–∏–º—É–º: {news_stats['min_news']}")
    
    # –¢–æ–ø-5 —Å–æ–±—ã—Ç–∏–π
    print(f"\nüî• –¢–æ–ø-5 —Å–∞–º—ã—Ö —Å–∏–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π:")
    top_events = PriceEvent.objects.filter(is_anomaly=True).select_related('coin').order_by(
        '-price_change_percent'
    )[:5]
    
    for event in top_events:
        print(f"  {event.coin.symbol.upper()} {event.date}: "
              f"{event.price_change_percent:+.2f}% "
              f"(–Ω–æ–≤–æ—Å—Ç–µ–π: {event.news_count})")
    
    print("\n" + "="*60)
    
    return {
        'total': total_events,
        'spikes': spikes,
        'crashes': crashes,
        'avg_change': changes['avg'],
        'avg_news': news_stats['avg_news']
    }


# ============================================
# –ú–ê–®–ò–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï
# ============================================

@shared_task
def prepare_training_dataset():
    """
    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
    
    –î–ª—è –∫–∞–∂–¥–æ–π –∞–Ω–æ–º–∞–ª–∏–∏ —Å–æ–±–∏—Ä–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏:
    - –¶–µ–Ω–æ–≤—ã–µ: —Å—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞, –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å, —Ç—Ä–µ–Ω–¥ –∑–∞ 7 –¥–Ω–µ–π –¥–æ —Å–æ–±—ã—Ç–∏—è
    - –ù–æ–≤–æ—Å—Ç–Ω—ã–µ: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π, —Å—Ä–µ–¥–Ω—è—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
    - –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: –ø—Ä–æ—Ü–µ–Ω—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã
    
    Returns:
        DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    """
    import pandas as pd
    import numpy as np
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –∞–Ω–æ–º–∞–ª–∏–∏ (–∏—Å–∫–ª—é—á–∞–µ–º —Å—Ç–µ–π–±–ª–∫–æ–∏–Ω—ã –±–µ–∑ –∞–Ω–æ–º–∞–ª–∏–π)
    events = PriceEvent.objects.filter(
        is_anomaly=True
    ).select_related('coin').order_by('date')
    
    if events.count() == 0:
        raise Exception("–ù–µ—Ç –∞–Ω–æ–º–∞–ª–∏–π! –ó–∞–ø—É—Å—Ç–∏—Ç–µ detect_all_anomalies()")
    
    print(f"üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ {events.count()} –∞–Ω–æ–º–∞–ª–∏–π...")
    
    data = []
    skipped = 0
    
    for event in events:
        try:
            coin = event.coin
            event_date = event.date
            
            # ============================================
            # 1. –¶–ï–ù–û–í–´–ï –ü–†–ò–ó–ù–ê–ö–ò (–∑–∞ 7 –¥–Ω–µ–π –î–û —Å–æ–±—ã—Ç–∏—è)
            # ============================================
            
            # –ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞: 7 –¥–Ω–µ–π –¥–æ —Å–æ–±—ã—Ç–∏—è
            period_start = event_date - timedelta(days=7)
            period_end = event_date - timedelta(days=1)  # –Ω–µ –≤–∫–ª—é—á–∞—è –¥–µ–Ω—å —Å–æ–±—ã—Ç–∏—è
            
            # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ü–µ–Ω
            price_stats = CoinDailyStat.objects.filter(
                coin=coin,
                date__range=[period_start, period_end]
            ).order_by('date')
            
            if price_stats.count() < 3:
                skipped += 1
                continue
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—ã
            prices = [float(s.price) for s in price_stats]
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            avg_price_7d = np.mean(prices)
            volatility_7d = np.std(prices)  # —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
            price_trend_7d = (prices[-1] - prices[0]) / prices[0] * 100  # —Ç—Ä–µ–Ω–¥ –≤ %
            
            # ============================================
            # 2. –ù–û–í–û–°–¢–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò (–∑–∞ 3 –¥–Ω—è –î–û —Å–æ–±—ã—Ç–∏—è)
            # ============================================
            
            news_period_start = event_date - timedelta(days=3)
            news_period_end = event_date
            
            news = NewsArticle.objects.filter(
                coin=coin,
                published_at__date__range=[news_period_start, news_period_end]
            ).prefetch_related('newssentiment')
            
            news_count_3d = news.count()
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
            sentiments = []
            for article in news:
                if hasattr(article, 'newssentiment'):
                    sentiments.append(article.newssentiment.sentiment_score)
            
            # –ü—Ä–∏–∑–Ω–∞–∫–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
            if sentiments:
                avg_sentiment = np.mean(sentiments)
                sentiment_std = np.std(sentiments)
                positive_ratio = len([s for s in sentiments if s > 0.1]) / len(sentiments)
                negative_ratio = len([s for s in sentiments if s < -0.1]) / len(sentiments)
                positive_count = len([s for s in sentiments if s > 0.1])
                negative_count = len([s for s in sentiments if s < -0.1])
                neutral_count = len([s for s in sentiments if -0.1 <= s <= 0.1])
            else:
                avg_sentiment = 0
                sentiment_std = 0
                positive_ratio = 0
                negative_ratio = 0
                positive_count = 0
                negative_count = 0
                neutral_count = 0
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            news_per_day = news_count_3d / 3.0
            news_spike = 1 if news_count_3d > 50 else 0  # –≤—Å–ø–ª–µ—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
            
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º –Ω–æ–≤–æ—Å—Ç–µ–π
            political_news = news.filter(news_type='political')
            financial_news = news.filter(news_type='financial')
            
            political_count = political_news.count()
            financial_count = financial_news.count()
            
            political_ratio = political_count / news_count_3d if news_count_3d > 0 else 0
            
            # –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
            political_sentiments = []
            for article in political_news:
                if hasattr(article, 'newssentiment'):
                    political_sentiments.append(article.newssentiment.sentiment_score)
            
            avg_political_sentiment = np.mean(political_sentiments) if political_sentiments else 0
            
            # ============================================
            # 3. –ö–û–ù–¢–ï–ö–°–¢–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò
            # ============================================
            
            # –î–µ–Ω—å –Ω–µ–¥–µ–ª–∏ (–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã —Ç–æ—Ä–≥—É—é—Ç—Å—è 24/7, –Ω–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–∞–∑–Ω–∞—è)
            day_of_week = event_date.weekday()  # 0=Monday, 6=Sunday
            
            # –ú–µ—Å—è—Ü (—Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å)
            month = event_date.month
            
            # ============================================
            # 4. –¶–ï–õ–ï–í–ê–Ø –ü–ï–†–ï–ú–ï–ù–ù–ê–Ø
            # ============================================
            
            target = float(event.price_change_percent)
            
            # ============================================
            # –°–û–•–†–ê–ù–ï–ù–ò–ï –ü–†–ò–ú–ï–†–ê
            # ============================================
            
            data.append({
                # –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
                'coin_symbol': coin.symbol,
                'date': event_date,
                
                # –¶–µ–Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                'avg_price_7d': avg_price_7d,
                'volatility_7d': volatility_7d,
                'price_trend_7d': price_trend_7d,
                
                # –ù–æ–≤–æ—Å—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)
                'news_count_3d': news_count_3d,
                'news_per_day': news_per_day,
                'news_spike': news_spike,
                
                # –ù–æ–≤–æ—Å—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å)
                'avg_sentiment': avg_sentiment,
                'sentiment_std': sentiment_std,
                'positive_ratio': positive_ratio,
                'negative_ratio': negative_ratio,
                'positive_count': positive_count,
                'negative_count': negative_count,
                'neutral_count': neutral_count,
                
                # –ù–æ–≤–æ—Å—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–ø–æ —Ç–∏–ø–∞–º)
                'political_count': political_count,
                'financial_count': financial_count,
                'political_ratio': political_ratio,
                'avg_political_sentiment': avg_political_sentiment,
                
                # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                'day_of_week': day_of_week,
                'month': month,
                
                # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
                'price_change_percent': target
            })
            
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–±—ã—Ç–∏—è {event.id}: {e}")
            skipped += 1
            continue
    
    print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {len(data)}")
    print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped}")
    
    if len(data) == 0:
        raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ!")
    
    # –°–æ–∑–¥–∞–µ–º DataFrame
    df = pd.DataFrame(data)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
    print(f"  –í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {len(df)}")
    print(f"  –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df.columns) - 3}")  # –∏—Å–∫–ª—é—á–∞—è coin_symbol, date, target
    print(f"  –°—Ä–µ–¥–Ω–∏–π % –∏–∑–º–µ–Ω–µ–Ω–∏—è: {df['price_change_percent'].mean():.2f}%")
    print(f"  Min –∏–∑–º–µ–Ω–µ–Ω–∏–µ: {df['price_change_percent'].min():.2f}%")
    print(f"  Max –∏–∑–º–µ–Ω–µ–Ω–∏–µ: {df['price_change_percent'].max():.2f}%")
    
    return df


@shared_task
def train_prediction_model():
    """
    –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ü–µ–Ω
    
    –ê–ª–≥–æ—Ä–∏—Ç–º:
    1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ (prepare_training_dataset)
    2. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test (80%/20%)
    3. –û–±—É—á–µ–Ω–∏–µ Gradient Boosting Regressor
    4. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (R¬≤, MAE)
    5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    
    Returns:
        Dict —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –º–æ–¥–µ–ª–∏
    """
    import pandas as pd
    import numpy as np
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import GradientBoostingRegressor
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import r2_score, mean_absolute_error
    import pickle
    import os
    
    print("="*60)
    print("ü§ñ –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –ú–ê–®–ò–ù–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
    print("="*60)
    
    # ============================================
    # 1. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•
    # ============================================
    
    print("\n[1/5] üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    df = prepare_training_dataset()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ (features) –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (target)
    feature_columns = [
        # –¶–µ–Ω–æ–≤—ã–µ
        'avg_price_7d', 'volatility_7d', 'price_trend_7d',
        
        # –ù–æ–≤–æ—Å—Ç–Ω—ã–µ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)
        'news_count_3d', 'news_per_day', 'news_spike',
        
        # –ù–æ–≤–æ—Å—Ç–Ω—ã–µ (—Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å)
        'avg_sentiment', 'sentiment_std', 
        'positive_ratio', 'negative_ratio',
        'positive_count', 'negative_count', 'neutral_count',
        
        # –ù–æ–≤–æ—Å—Ç–Ω—ã–µ (–ø–æ —Ç–∏–ø–∞–º)
        'political_count', 'financial_count', 
        'political_ratio', 'avg_political_sentiment',
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ
        'day_of_week', 'month'
    ]
    
    X = df[feature_columns].values
    y = df['price_change_percent'].values
    
    print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –≥–æ—Ç–æ–≤: {X.shape[0]} –ø—Ä–∏–º–µ—Ä–æ–≤, {X.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    # ============================================
    # 2. –†–ê–ó–î–ï–õ–ï–ù–ò–ï –ù–ê TRAIN/TEST
    # ============================================
    
    print("\n[2/5] üîÄ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, 
        test_size=0.2,  # 20% –Ω–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        random_state=42,
        shuffle=True
    )
    
    print(f"‚úÖ Train: {len(X_train)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    print(f"‚úÖ Test:  {len(X_test)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    # ============================================
    # 3. –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –ü–†–ò–ó–ù–ê–ö–û–í
    # ============================================
    
    print("\n[3/5] üìè –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print("‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã (StandardScaler)")
    
    # ============================================
    # 4. –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò
    # ============================================
    
    print("\n[4/5] üß† –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (Gradient Boosting)...")
    
    model = GradientBoostingRegressor(
        n_estimators=30,       # –±—ã–ª–æ 100 ‚Üí —Å—Ç–∞–ª–æ 30
        learning_rate=0.05,    # –±—ã–ª–æ 0.1 ‚Üí —Å—Ç–∞–ª–æ 0.05
        max_depth=3,           # –±—ã–ª–æ 5 ‚Üí —Å—Ç–∞–ª–æ 3
        min_samples_split=20,  # –±—ã–ª–æ 5 ‚Üí —Å—Ç–∞–ª–æ 20
        min_samples_leaf=10,   # –±—ã–ª–æ 3 ‚Üí —Å—Ç–∞–ª–æ 10
        subsample=0.8,
        random_state=42,
        verbose=0
    )
    
    model.fit(X_train_scaled, y_train)
    
    print("‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!")
    
    # ============================================
    # 5. –û–¶–ï–ù–ö–ê –ö–ê–ß–ï–°–¢–í–ê
    # ============================================
    
    print("\n[5/5] üìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞...")
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_train_pred = model.predict(X_train_scaled)
    y_test_pred = model.predict(X_test_scaled)
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    train_r2 = r2_score(y_train, y_train_pred)
    test_r2 = r2_score(y_test, y_test_pred)
    
    train_mae = mean_absolute_error(y_train, y_train_pred)
    test_mae = mean_absolute_error(y_test, y_test_pred)
    
    print(f"‚úÖ Train R¬≤ Score: {train_r2:.4f}")
    print(f"‚úÖ Test R¬≤ Score:  {test_r2:.4f}")
    print(f"‚úÖ Train MAE:      {train_mae:.2f}%")
    print(f"‚úÖ Test MAE:       {test_mae:.2f}%")
    
    # Feature importance (–≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
    feature_importance = pd.DataFrame({
        'feature': feature_columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(f"\nüìä –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    for i, row in feature_importance.head(10).iterrows():
        print(f"  {row['feature']:25} {row['importance']:.4f}")
    
    # ============================================
    # 6. –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò
    # ============================================
    
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    
    model_data = {
        'model': model,
        'scaler': scaler,
        'feature_columns': feature_columns,
        'train_r2': train_r2,
        'test_r2': test_r2,
        'train_mae': train_mae,
        'test_mae': test_mae,
        'trained_at': datetime.now(),
        'examples_count': len(X)
    }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–ø–∫—É –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    model_path = os.path.join(os.path.dirname(__file__), 'ml_model.pkl')
    with open(model_path, 'wb') as f:
        pickle.dump(model_data, f)
    
    print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
    
    print("\n" + "="*60)
    
    return {
        'examples': len(X),
        'features': len(feature_columns),
        'train_r2': train_r2,
        'test_r2': test_r2,
        'train_mae': train_mae,
        'test_mae': test_mae,
        'feature_importance': feature_importance.to_dict('records')
    }


@shared_task
def predict_price_change(coin_symbol):
    """
    –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –±—É–¥—É—â–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–Ω–µ—Ç—ã
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏ —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
    
    Args:
        coin_symbol: —Å–∏–º–≤–æ–ª –º–æ–Ω–µ—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'btc')
    
    Returns:
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã –≤ %
    """
    import pickle
    import os
    import numpy as np
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model_path = os.path.join(os.path.dirname(__file__), 'ml_model.pkl')
    
    if not os.path.exists(model_path):
        raise Exception("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞! –ó–∞–ø—É—Å—Ç–∏—Ç–µ train_prediction_model()")
    
    with open(model_path, 'rb') as f:
        model_data = pickle.load(f)
    
    model = model_data['model']
    scaler = model_data['scaler']
    feature_columns = model_data['feature_columns']
    
    # –ü–æ–ª—É—á–∞–µ–º –º–æ–Ω–µ—Ç—É
    try:
        coin = CoinSnapshot.objects.get(symbol=coin_symbol.lower())
    except CoinSnapshot.DoesNotExist:
        raise Exception(f"–ú–æ–Ω–µ—Ç–∞ {coin_symbol} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—É—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ prepare_training_dataset)
    today = datetime.now().date()
    
    # –¶–µ–Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π)
    period_start = today - timedelta(days=7)
    price_stats = CoinDailyStat.objects.filter(
        coin=coin,
        date__range=[period_start, today]
    ).order_by('date')
    
    if price_stats.count() < 3:
        raise Exception(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {coin_symbol}")
    
    prices = [float(s.price) for s in price_stats]
    avg_price_7d = np.mean(prices)
    volatility_7d = np.std(prices)
    price_trend_7d = (prices[-1] - prices[0]) / prices[0] * 100
    
    # –ù–æ–≤–æ—Å—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–Ω—è)
    news_period_start = today - timedelta(days=3)
    news = NewsArticle.objects.filter(
        coin=coin,
        published_at__date__range=[news_period_start, today]
    ).prefetch_related('newssentiment')
    
    news_count_3d = news.count()
    
    sentiments = []
    for article in news:
        if hasattr(article, 'newssentiment'):
            sentiments.append(article.newssentiment.sentiment_score)
    
    if sentiments:
        avg_sentiment = np.mean(sentiments)
        sentiment_std = np.std(sentiments)
        positive_ratio = len([s for s in sentiments if s > 0.1]) / len(sentiments)
        negative_ratio = len([s for s in sentiments if s < -0.1]) / len(sentiments)
        positive_count = len([s for s in sentiments if s > 0.1])
        negative_count = len([s for s in sentiments if s < -0.1])
        neutral_count = len([s for s in sentiments if -0.1 <= s <= 0.1])
    else:
        avg_sentiment = 0
        sentiment_std = 0
        positive_ratio = 0
        negative_ratio = 0
        positive_count = 0
        negative_count = 0
        neutral_count = 0
    
    news_per_day = news_count_3d / 3.0
    news_spike = 1 if news_count_3d > 50 else 0
    
    political_count = news.filter(news_type='political').count()
    financial_count = news.filter(news_type='financial').count()
    political_ratio = political_count / news_count_3d if news_count_3d > 0 else 0
    
    political_sentiments = []
    for article in news.filter(news_type='political'):
        if hasattr(article, 'newssentiment'):
            political_sentiments.append(article.newssentiment.sentiment_score)
    avg_political_sentiment = np.mean(political_sentiments) if political_sentiments else 0
    
    day_of_week = today.weekday()
    month = today.month
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    features = {
        'avg_price_7d': avg_price_7d,
        'volatility_7d': volatility_7d,
        'price_trend_7d': price_trend_7d,
        'news_count_3d': news_count_3d,
        'news_per_day': news_per_day,
        'news_spike': news_spike,
        'avg_sentiment': avg_sentiment,
        'sentiment_std': sentiment_std,
        'positive_ratio': positive_ratio,
        'negative_ratio': negative_ratio,
        'positive_count': positive_count,
        'negative_count': negative_count,
        'neutral_count': neutral_count,
        'political_count': political_count,
        'financial_count': financial_count,
        'political_ratio': political_ratio,
        'avg_political_sentiment': avg_political_sentiment,
        'day_of_week': day_of_week,
        'month': month
    }
    
    X = np.array([[features[col] for col in feature_columns]])
    X_scaled = scaler.transform(X)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    prediction = model.predict(X_scaled)[0]
    
    return {
        'coin': coin_symbol.upper(),
        'predicted_change': round(prediction, 2),
        'current_price': float(coin.price),
        'news_count': news_count_3d,
        'avg_sentiment': round(avg_sentiment, 2)
    }



logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)





# –ü–æ–∫–∞ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–∫–∏, –æ–Ω–∞ –Ω–µ –∑–∞—Ä–∞–±–æ—Ç–∞–ª–∞ —É –º–µ–Ω—è, –ø–æ –∏–¥–µ–µ –¥–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ –º–µ–Ω—è—Ç—å Celery
#  –Ω–∞ –¥—Ä—É–≥—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Ä–∞—Å—Å—ã–ª–∫–∏
TELEGRAM_API_URL = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"

@shared_task
def send_price_updates():
    subscriptions = Subscription.objects.select_related("user", "coin").all()
    user_messages = {}

    for sub in subscriptions:
        user_id = sub.user.telegram_id
        coin = sub.coin
        text = f"{coin.name} ({coin.symbol}): ${coin.price:.2f}"
        user_messages.setdefault(user_id, []).append(text)

    for user_id, messages in user_messages.items():
        full_message = "–í–∞—à–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞–º:\n\n" + "\n".join(messages)
        try:
            response = requests.post(TELEGRAM_API_URL, data={
                "chat_id": user_id,
                "text": full_message
            }, timeout=10)
            if not response.ok:
                print(f"[Telegram] –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ {user_id}: {response.text}")
        except Exception as e:
            print(f"[Celery] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}: {e}")

